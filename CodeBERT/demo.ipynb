{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModel\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "nl_tokens=tokenizer.tokenize(\"return maximum value\")\n",
    "code_tokens=tokenizer.tokenize(\"def max(a,b): if a>b: return a else return b\")\n",
    "tokens=[tokenizer.cls_token]+nl_tokens+[tokenizer.sep_token]+code_tokens+[tokenizer.sep_token]\n",
    "tokens_ids=tokenizer.convert_tokens_to_ids(tokens)\n",
    "context_embeddings=model(torch.tensor(tokens_ids)[None,:])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 30921,  4532,   923,     2,  9232, 19220,  1640,   102,     6,\n",
       "           428,  3256,   114,    10, 15698,   428,    35,   671,    10,  1493,\n",
       "           671,   741,     2]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(tokens_ids)[None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_embeddings=model(torch.tensor(tokens_ids)[None,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.1423,  0.3766,  0.0443,  ..., -0.2513, -0.3099,  0.3183],\n",
       "         [-0.5739,  0.1333,  0.2314,  ..., -0.1240, -0.1219,  0.2033],\n",
       "         [-0.1579,  0.1335,  0.0291,  ...,  0.2340, -0.8801,  0.6216],\n",
       "         ...,\n",
       "         [-0.4042,  0.2284,  0.5241,  ..., -0.2046, -0.2419,  0.7031],\n",
       "         [-0.3894,  0.4603,  0.4797,  ..., -0.3335, -0.6049,  0.4730],\n",
       "         [-0.1433,  0.3785,  0.0450,  ..., -0.2527, -0.3121,  0.3207]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 4.7150e-01, -3.5630e-01, -5.4936e-01,  1.3725e-01,  3.5625e-01,\n",
       "          7.5766e-02,  4.8255e-01, -3.2027e-01,  1.1819e-01, -2.9700e-01,\n",
       "          4.2410e-01,  3.2094e-02, -2.4457e-01,  1.3310e-01, -3.7926e-02,\n",
       "          5.7377e-01,  4.3760e-01, -5.0825e-01,  9.6078e-02,  3.2665e-01,\n",
       "         -3.4262e-01,  5.0699e-01,  3.5128e-01,  1.8717e-02, -3.9835e-02,\n",
       "          2.5501e-01,  1.4031e-01,  1.0210e-01,  5.0947e-01,  1.1313e-01,\n",
       "          1.2371e-01,  1.1464e-01,  2.2844e-01, -3.1970e-02, -3.3215e-01,\n",
       "         -6.8749e-02, -5.1184e-01,  1.6977e-01,  6.7131e-01, -3.2628e-01,\n",
       "         -3.8377e-01,  7.4273e-02, -6.8942e-04, -3.4939e-01,  9.0969e-02,\n",
       "          6.2035e-01,  1.7675e-01,  4.6117e-02, -2.5497e-01, -2.3113e-01,\n",
       "         -5.0186e-01,  4.2327e-01,  3.5368e-01,  1.7222e-01, -2.6715e-01,\n",
       "          1.0864e-01,  5.4042e-02, -1.1332e-01, -4.4852e-02, -3.0077e-01,\n",
       "         -4.3864e-01, -4.3522e-01,  9.4901e-02,  1.8217e-01, -9.7902e-02,\n",
       "         -1.9677e-01,  4.2082e-01, -6.6876e-03, -3.5769e-01,  6.7084e-02,\n",
       "         -3.1553e-01,  1.8750e-01,  2.3914e-02, -7.3181e-01, -1.3898e-01,\n",
       "          4.5335e-02, -5.9944e-01,  9.3544e-02,  6.3602e-01,  4.1679e-01,\n",
       "         -7.9092e-02,  3.6736e-01, -8.0382e-03,  2.9941e-01, -1.6076e-01,\n",
       "         -3.0384e-01,  5.1170e-01, -1.3831e-01,  1.6045e-01,  3.7391e-01,\n",
       "         -3.3445e-01, -6.7519e-01, -1.4210e-01,  1.8189e-01, -2.5990e-01,\n",
       "          1.6391e-01, -1.6414e-02,  1.0273e-01, -3.8033e-01, -6.6687e-02,\n",
       "          1.8135e-01, -2.3828e-01, -1.0356e-01,  2.5820e-01,  3.2418e-01,\n",
       "         -2.6027e-01, -2.1682e-01,  8.5748e-02,  1.5879e-01, -1.7025e-01,\n",
       "         -1.7295e-01,  6.2137e-01,  5.4918e-01,  1.3207e-01,  1.3636e-01,\n",
       "          9.5092e-02, -2.0541e-01, -3.8181e-01,  3.9268e-01, -4.0351e-01,\n",
       "          2.4018e-01, -1.7088e-01,  9.1052e-02,  3.0489e-01, -3.6329e-01,\n",
       "          2.2154e-01,  6.1791e-02,  4.8088e-01,  2.0752e-01, -8.5311e-02,\n",
       "          1.3011e-02, -4.4674e-02, -4.2074e-02,  2.1927e-01, -2.9866e-02,\n",
       "          7.4617e-02,  1.8460e-01, -7.4268e-01, -3.9923e-01,  5.5859e-01,\n",
       "          7.7902e-01,  1.1659e-01,  2.1286e-01,  2.3008e-01,  4.9141e-01,\n",
       "          5.8862e-01,  2.4523e-01, -5.6102e-01,  1.8004e-02,  3.2355e-01,\n",
       "         -7.9384e-02, -8.9981e-02, -2.6756e-01, -4.9264e-01, -6.1535e-01,\n",
       "         -8.4458e-02,  3.4616e-01, -3.8762e-02,  4.8556e-03,  6.0517e-01,\n",
       "          2.3117e-01, -4.1828e-01, -2.2209e-01, -1.9095e-01, -1.9957e-01,\n",
       "         -3.7328e-01, -1.5503e-01, -4.6464e-02, -4.2456e-01, -4.2328e-01,\n",
       "          1.7607e-02, -5.4650e-01, -5.4455e-02,  2.9689e-01, -5.5177e-01,\n",
       "          5.8491e-01, -5.4295e-01,  1.3820e-01,  5.0009e-01, -3.8773e-01,\n",
       "          1.2097e-01, -4.8211e-01,  1.5659e-02,  3.9361e-01,  6.6494e-02,\n",
       "          2.9648e-01, -2.8375e-01,  4.5502e-01, -3.6438e-02,  2.3582e-01,\n",
       "          2.3416e-01,  4.1153e-02, -3.0964e-01,  3.2444e-01, -4.5188e-01,\n",
       "          2.0224e-01, -3.7423e-01, -1.2541e-01, -3.4953e-01, -3.3252e-01,\n",
       "          2.1102e-01, -7.8654e-01, -5.7148e-01,  6.5256e-02, -1.2183e-01,\n",
       "          3.5744e-02, -6.8682e-02,  6.9127e-02,  6.6874e-02, -1.1945e-01,\n",
       "          3.5370e-02, -4.4271e-01,  3.8747e-01, -2.7510e-01, -2.1269e-01,\n",
       "         -4.4608e-02,  3.3367e-01,  3.9946e-01,  2.2848e-01, -5.2057e-01,\n",
       "         -3.7341e-01,  1.8708e-01,  4.6949e-01, -1.5274e-01,  5.8486e-01,\n",
       "         -1.9228e-01, -2.5796e-01,  1.3754e-02,  3.0778e-01,  1.4401e-01,\n",
       "          5.4812e-01, -3.3283e-01, -6.7202e-02,  6.3477e-02, -5.5560e-01,\n",
       "         -3.2160e-01, -2.4019e-01,  2.3602e-01,  4.5465e-01,  5.0987e-02,\n",
       "          1.9036e-01,  3.8832e-01,  2.8965e-01,  9.7908e-04,  4.2943e-01,\n",
       "         -2.0699e-01,  2.0497e-01, -5.0250e-01, -4.4906e-02, -4.6455e-01,\n",
       "         -3.9289e-01, -4.7725e-01,  7.0676e-01, -3.0514e-01,  4.8527e-01,\n",
       "          5.1996e-01, -3.6131e-01, -2.3683e-01,  2.5103e-01,  1.4420e-01,\n",
       "          1.6731e-01, -2.1525e-02,  4.2732e-02,  2.0653e-01,  6.1418e-02,\n",
       "          3.2693e-01,  5.4063e-01,  2.4597e-01,  3.5719e-01, -2.8640e-02,\n",
       "          5.1998e-02,  3.8828e-01, -1.6048e-01, -1.6528e-01, -3.6662e-02,\n",
       "          1.5690e-01, -2.3536e-01, -4.0941e-01,  5.6858e-03, -1.5256e-02,\n",
       "          5.9498e-01, -1.2031e-01, -3.6745e-01,  2.1133e-01,  2.6462e-01,\n",
       "         -5.8668e-01,  1.7116e-01,  1.6690e-01,  1.9139e-01, -4.7906e-01,\n",
       "         -9.8389e-02,  2.8645e-02,  2.3332e-01, -5.3467e-01, -4.4716e-01,\n",
       "          5.3268e-01, -1.4907e-02,  2.9006e-01,  2.3184e-01, -3.3034e-01,\n",
       "         -2.6584e-01,  7.5369e-01, -1.2564e-01, -4.8470e-01,  3.4966e-01,\n",
       "          1.4615e-01, -4.0907e-03,  2.3662e-01,  1.8143e-01,  3.6854e-01,\n",
       "         -2.5944e-01,  4.9650e-01,  2.2138e-01, -6.0010e-01, -4.2269e-01,\n",
       "         -2.3369e-01,  1.3181e-02, -1.2124e-02, -3.1303e-01, -5.0705e-01,\n",
       "          6.9887e-02,  2.1473e-01, -1.9539e-01,  3.1861e-01,  2.3153e-01,\n",
       "          3.4193e-01, -5.0482e-02,  4.9556e-01, -2.7507e-01,  5.2601e-01,\n",
       "         -6.7061e-02,  5.5727e-01, -5.0674e-01, -9.6778e-02, -6.2651e-02,\n",
       "         -1.8241e-01, -2.6070e-02, -1.1592e-02,  3.6547e-01, -2.5384e-01,\n",
       "         -5.5893e-01,  2.1534e-01,  2.5125e-01,  1.8956e-01,  2.6512e-01,\n",
       "          4.2718e-01,  1.9433e-01,  1.6704e-01,  5.3003e-02,  3.2565e-01,\n",
       "          2.6725e-01, -2.6000e-01, -6.8822e-01,  2.7509e-01, -4.2993e-01,\n",
       "         -5.4566e-02, -2.2241e-01, -3.2658e-01,  6.8681e-01, -2.9542e-01,\n",
       "          2.2035e-01,  4.0749e-01,  2.7013e-01,  2.3533e-01,  4.7963e-02,\n",
       "          2.5444e-01,  2.6936e-01,  1.6109e-01,  1.2549e-01, -4.9040e-03,\n",
       "         -3.6403e-01, -3.4355e-01, -1.9132e-01,  1.9758e-01, -3.3804e-01,\n",
       "         -5.0776e-01,  1.3081e-01,  5.2014e-01,  1.3454e-01, -3.0617e-01,\n",
       "          3.6661e-01,  3.4424e-01,  1.8081e-01,  3.5509e-02, -2.1575e-01,\n",
       "         -4.1313e-02,  6.1423e-01, -8.9555e-02,  1.9317e-01,  7.2813e-01,\n",
       "          2.6257e-01, -5.2370e-01, -1.2850e-01, -2.4695e-01,  1.0069e-01,\n",
       "          1.6775e-01, -3.0791e-01,  2.5273e-01,  4.8728e-01,  3.0853e-01,\n",
       "          7.4176e-01,  6.7230e-02,  1.0636e-01,  9.8209e-02,  2.6368e-01,\n",
       "         -3.8011e-02,  1.1192e-01,  6.8359e-02,  5.2112e-01,  4.5077e-01,\n",
       "         -4.0663e-01,  6.3565e-02, -2.3371e-01, -1.0180e-01, -1.9403e-01,\n",
       "         -4.5389e-01, -2.3603e-02,  3.4243e-01, -5.7785e-01,  5.3025e-02,\n",
       "         -2.1306e-01,  1.2486e-01, -7.7958e-02, -1.1459e-01, -2.3934e-01,\n",
       "         -3.6969e-01,  6.6755e-01, -4.4622e-02, -6.7890e-02, -4.4609e-01,\n",
       "         -3.7969e-01,  5.6199e-02,  2.5801e-01, -3.0728e-01, -2.2405e-01,\n",
       "          4.7990e-01, -6.0981e-02, -8.0518e-02, -1.8612e-01,  2.6739e-01,\n",
       "         -1.9170e-01,  2.2647e-01,  2.5510e-01, -1.9470e-01, -2.5384e-01,\n",
       "          4.2527e-02, -3.9443e-01, -3.0376e-01, -5.2529e-01,  5.3021e-01,\n",
       "         -3.4430e-01, -1.8013e-01, -2.5343e-01, -6.1526e-01,  1.4404e-01,\n",
       "          2.9875e-01,  5.0161e-01, -3.4345e-01,  7.1556e-02,  7.9518e-01,\n",
       "         -9.5669e-02, -3.9364e-01, -2.1511e-02,  3.5703e-01, -7.6181e-02,\n",
       "          6.4324e-01,  5.1370e-01, -2.8053e-02,  1.4438e-01,  7.0648e-01,\n",
       "          9.5706e-03,  2.2431e-01, -2.8596e-01,  5.4215e-01, -9.2518e-02,\n",
       "          2.7932e-01,  3.9295e-02,  4.2468e-02, -1.4064e-02, -1.3282e-01,\n",
       "          3.8706e-01,  5.0100e-01, -6.7448e-01, -2.0460e-01,  1.6848e-01,\n",
       "          3.9042e-02, -2.2823e-01, -4.0191e-01, -1.7211e-01, -3.4232e-01,\n",
       "         -1.3590e-01, -1.4437e-01, -2.9545e-02, -4.8072e-01, -1.3908e-01,\n",
       "          2.9797e-01, -4.3536e-01,  1.2373e-01,  5.8039e-01, -1.3874e-02,\n",
       "          3.2609e-01, -4.0192e-01, -1.0719e-01,  3.5052e-01, -1.8303e-01,\n",
       "         -3.8228e-01,  1.8405e-01,  8.2679e-01, -2.5431e-01, -7.2688e-01,\n",
       "         -8.2039e-02,  3.9905e-01,  7.0849e-02,  1.8274e-01, -1.3120e-01,\n",
       "         -3.1111e-01,  1.2992e-01, -3.9694e-03,  1.0619e-01, -2.5064e-01,\n",
       "         -5.7840e-01, -2.5462e-01,  5.9697e-01, -6.1520e-01,  1.0214e-01,\n",
       "         -1.9764e-01, -1.4609e-03, -4.5013e-01,  2.3693e-01, -3.4721e-01,\n",
       "          6.6259e-01,  1.6625e-01, -5.6758e-01,  9.6310e-02,  6.9446e-02,\n",
       "         -7.2585e-02, -1.8014e-01, -2.4379e-01,  6.9398e-01, -3.8704e-01,\n",
       "         -7.9208e-01,  2.0151e-01,  2.6923e-01,  6.1998e-01, -2.7474e-01,\n",
       "         -6.2203e-02, -2.3122e-01,  2.4636e-01,  1.8550e-01,  2.6231e-02,\n",
       "         -2.1962e-01, -1.7183e-01, -5.4883e-01, -3.5937e-01, -5.1406e-01,\n",
       "          9.1436e-02,  1.1488e-01, -5.7784e-01,  2.5833e-01, -1.8207e-01,\n",
       "          3.0372e-01,  2.0767e-01, -3.6477e-01, -1.1704e-01,  3.9381e-01,\n",
       "          4.9612e-01,  2.4522e-01,  4.8964e-01,  2.3969e-01,  2.0205e-01,\n",
       "         -2.3134e-01,  1.6578e-01,  1.7401e-01, -1.1840e-01,  4.8620e-01,\n",
       "         -1.2857e-01, -6.0959e-01, -1.0752e-01,  7.2374e-01,  9.1091e-02,\n",
       "         -3.1621e-01, -3.8739e-02,  5.6857e-01,  1.6417e-01,  6.5136e-02,\n",
       "          2.8403e-01, -3.6679e-01, -2.3089e-01, -8.1413e-02, -7.0643e-02,\n",
       "         -4.4547e-01, -2.5528e-01, -7.1425e-02, -1.6862e-01, -2.9600e-01,\n",
       "         -9.7780e-02, -2.1621e-01,  3.8336e-01, -5.9464e-01, -9.2590e-02,\n",
       "         -1.2593e-01, -6.0687e-02, -2.8613e-01,  1.4779e-01,  1.9601e-01,\n",
       "          3.3654e-02,  8.4509e-02,  6.2976e-01, -1.2104e-01, -1.3800e-01,\n",
       "         -1.9134e-01, -2.4629e-01,  2.8341e-01, -2.9735e-01,  9.6018e-02,\n",
       "         -1.0077e-01,  3.1462e-01, -6.0030e-01, -2.5460e-01, -1.9528e-02,\n",
       "         -2.6962e-01, -4.2408e-01,  4.2981e-01,  2.5030e-01,  1.8447e-01,\n",
       "          5.1850e-01,  1.0309e-01,  5.0028e-02, -3.3568e-01, -3.9747e-01,\n",
       "         -2.2378e-01,  2.2532e-01,  1.0714e-02, -4.5273e-01, -2.1252e-01,\n",
       "          2.4876e-01, -4.8858e-01, -2.6339e-01,  3.2927e-01,  1.3553e-02,\n",
       "         -1.7327e-01, -2.2427e-01, -1.2759e-01, -6.6241e-01,  1.6697e-01,\n",
       "          1.5629e-01,  5.9488e-02, -2.4215e-01,  9.7270e-02, -2.1717e-01,\n",
       "          1.8135e-01,  2.3422e-01,  8.6560e-02, -1.5329e-01, -4.1795e-01,\n",
       "         -4.8714e-01, -2.9459e-01,  6.0243e-02,  3.5235e-01, -2.0245e-01,\n",
       "         -2.5684e-01,  1.4232e-01,  3.1399e-01, -2.0319e-01,  7.0800e-02,\n",
       "          1.6357e-01, -6.4515e-01, -1.8682e-01, -6.6109e-02,  1.3510e-01,\n",
       "         -3.6946e-02, -2.6406e-01, -4.3013e-01,  2.9970e-01, -9.4760e-02,\n",
       "         -2.5095e-01,  5.7827e-01, -2.6084e-01,  3.7674e-01, -2.0460e-02,\n",
       "         -3.5603e-01, -1.6051e-01,  4.1703e-01, -3.5669e-02,  3.2511e-01,\n",
       "          1.1295e-01, -5.7512e-01, -9.0615e-02, -3.5656e-02, -2.4763e-01,\n",
       "         -3.0538e-01, -1.4580e-01, -1.2630e-01,  3.2649e-01, -6.0801e-01,\n",
       "          4.1994e-01,  6.9675e-02,  1.7676e-01,  2.0794e-01, -4.2390e-01,\n",
       "         -2.8855e-01,  2.4554e-01,  3.6714e-01, -2.7623e-01, -5.1691e-01,\n",
       "         -4.4558e-01, -3.2430e-01, -3.5839e-01, -2.6122e-01,  5.9469e-01,\n",
       "         -1.0930e-01, -2.6444e-01, -2.3977e-01,  5.3839e-01,  1.3591e-01,\n",
       "          2.4636e-02,  3.9281e-01,  1.7079e-01,  1.4576e-01,  2.2233e-01,\n",
       "         -7.1730e-01,  2.3906e-01, -3.9706e-01,  1.0233e-02, -8.8450e-02,\n",
       "          2.3844e-01, -2.8507e-01,  5.7868e-02, -3.1230e-01,  1.1013e-01,\n",
       "          3.9213e-01, -4.0828e-01, -1.3651e-01,  3.5180e-01,  2.4810e-01,\n",
       "         -3.4044e-01,  5.6891e-02,  1.9236e-01,  3.7451e-01,  1.3114e-01,\n",
       "          1.2152e-01,  4.4694e-01, -4.6215e-01, -1.6963e-02, -4.5601e-01,\n",
       "         -5.4624e-01,  2.1167e-01,  1.5431e-01,  3.8411e-01, -1.3819e-01,\n",
       "         -3.6989e-01,  6.3714e-01,  4.6063e-02, -5.4511e-02,  3.1150e-01,\n",
       "         -2.9491e-03, -6.1461e-02, -2.2618e-01,  2.3157e-01,  5.9729e-01,\n",
       "         -6.2527e-02,  8.4885e-02,  4.4153e-01, -5.6138e-01,  3.7571e-01,\n",
       "         -1.0708e-01, -1.5488e-02,  7.2278e-02]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1423,  0.3766,  0.0443,  ..., -0.2513, -0.3099,  0.3183],\n",
       "         [-0.5739,  0.1333,  0.2314,  ..., -0.1240, -0.1219,  0.2033],\n",
       "         [-0.1579,  0.1335,  0.0291,  ...,  0.2340, -0.8801,  0.6216],\n",
       "         ...,\n",
       "         [-0.4042,  0.2284,  0.5241,  ..., -0.2046, -0.2419,  0.7031],\n",
       "         [-0.3894,  0.4603,  0.4797,  ..., -0.3335, -0.6049,  0.4730],\n",
       "         [-0.1433,  0.3785,  0.0450,  ..., -0.2527, -0.3121,  0.3207]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 23, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from data_structure.question import QuestionDataset\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "tab_vocab_path = \"../data/tags/20211110/ts1000/_2_1_commonTags.csv\"\n",
    "tag_vocab = pd.read_csv(tab_vocab_path)\n",
    "tag_list = tag_vocab[\"tag\"].astype(str).tolist()\n",
    "mlb = preprocessing.MultiLabelBinarizer()\n",
    "mlb.fit([tag_list])\n",
    "\n",
    "input_train = \"../data/questions/Train_Questions54.csv\"\n",
    "input_valid = \"../data/questions/Valid_Questions54.csv\"\n",
    "\n",
    "train = pd.read_csv(input_train)\n",
    "valid = pd.read_csv(input_valid)\n",
    "training_set = QuestionDataset(train, mlb, tokenizer)\n",
    "valid_set = QuestionDataset(valid, mlb, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(mlb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
